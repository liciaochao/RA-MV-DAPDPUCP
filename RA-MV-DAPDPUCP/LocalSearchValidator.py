import numpy as np
import matplotlib.pyplot as plt
import time
import copy
from typing import Dict, List, Tuple
import pandas as pd


class LocalSearchValidator:
    """
    å±€éƒ¨æœç´¢æœ‰æ•ˆæ€§éªŒè¯å·¥å…·
    ç”¨äºæ£€æµ‹å’Œåˆ†æå±€éƒ¨æœç´¢çš„å®é™…æ•ˆæœ
    """

    def __init__(self, dynamic_optimizer):
        self.dyn_opt = dynamic_optimizer
        self.validation_results = {
            'trigger_analysis': {},
            'operator_performance': {},
            'improvement_tracking': {},
            'time_analysis': {},
            'convergence_analysis': {}
        }

    def run_comprehensive_validation(self, num_tests: int = 1000):
        """
        è¿è¡Œå®Œæ•´çš„å±€éƒ¨æœç´¢éªŒè¯æµ‹è¯•
        """
        print("\n" + "=" * 80)
        print("ğŸ” å¼€å§‹å±€éƒ¨æœç´¢æœ‰æ•ˆæ€§ç»¼åˆéªŒè¯")
        print("=" * 80)

        # 1. è§¦å‘æœºåˆ¶éªŒè¯
        self.validate_trigger_mechanism()

        # 2. å•ç®—å­æ•ˆæœæµ‹è¯•
        self.validate_individual_operators()

        # 3. æ”¹è¿›è¿½è¸ªæµ‹è¯•
        self.track_improvement_patterns(num_tests)

        # 4. æ—¶é—´æ•ˆç‡åˆ†æ
        self.analyze_time_efficiency()

        # 5. æ”¶æ•›æ€§åˆ†æ
        self.analyze_convergence_behavior()

        # 6. å¯¹æ¯”æµ‹è¯•ï¼ˆæœ‰/æ— å±€éƒ¨æœç´¢ï¼‰
        self.comparative_analysis(num_tests)

        # 7. ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        self.generate_validation_report()

        return self.validation_results

    def validate_trigger_mechanism(self):
        """
        éªŒè¯å±€éƒ¨æœç´¢è§¦å‘æœºåˆ¶æ˜¯å¦æ­£å¸¸å·¥ä½œ
        """
        print("\nğŸ“Œ æµ‹è¯•1: å±€éƒ¨æœç´¢è§¦å‘æœºåˆ¶éªŒè¯")
        print("-" * 40)

        trigger_tests = []
        test_scenarios = [
            ("æˆæœ¬æ”¹è¿›åœºæ™¯", 1000, 900),  # æœ‰æ”¹è¿›
            ("æˆæœ¬æŒå¹³åœºæ™¯", 1000, 1000),  # æ— æ”¹è¿›
            ("å°å¹…æ¶åŒ–åœºæ™¯", 1000, 1050),  # 5%æ¶åŒ–
            ("å¤§å¹…æ¶åŒ–åœºæ™¯", 1000, 1400),  # 40%æ¶åŒ–
        ]

        # ä¿å­˜åŸå§‹è®¾ç½®
        original_theta = self.dyn_opt.theta
        original_count = self.dyn_opt.ls_operation_count

        for scenario_name, cost_before, cost_after in test_scenarios:
            # æµ‹è¯•æ¯ç§åœºæ™¯
            for truck_id in range(len(self.dyn_opt.TRUCK_Routes)):
                should_trigger, reason = self.dyn_opt.enhanced_local_search_trigger(
                    truck_id, cost_before, cost_after
                )

                trigger_tests.append({
                    'scenario': scenario_name,
                    'cost_before': cost_before,
                    'cost_after': cost_after,
                    'improvement_rate': (cost_before - cost_after) / cost_before * 100,
                    'triggered': should_trigger,
                    'reason': reason
                })

                print(f"  {scenario_name}: {cost_before}â†’{cost_after} | "
                      f"è§¦å‘={should_trigger} | åŸå› ={reason}")
                break  # åªæµ‹è¯•ç¬¬ä¸€ä¸ªè½¦è¾†å¯¹

        # æ¢å¤åŸå§‹è®¾ç½®
        self.dyn_opt.theta = original_theta
        self.dyn_opt.ls_operation_count = original_count

        # åˆ†æè§¦å‘ç‡
        trigger_rate = sum(1 for t in trigger_tests if t['triggered']) / len(trigger_tests) * 100
        print(f"\n  ğŸ“Š è§¦å‘ç‡: {trigger_rate:.1f}%")

        self.validation_results['trigger_analysis'] = {
            'tests': trigger_tests,
            'trigger_rate': trigger_rate
        }

        return trigger_rate > 50  # æœŸæœ›è‡³å°‘50%çš„åœºæ™¯è§¦å‘

    def validate_individual_operators(self):
        """
        éªŒè¯æ¯ä¸ªå±€éƒ¨æœç´¢ç®—å­çš„ç‹¬ç«‹æ•ˆæœ
        """
        print("\nğŸ“Œ æµ‹è¯•2: å±€éƒ¨æœç´¢ç®—å­ç‹¬ç«‹æ•ˆæœéªŒè¯")
        print("-" * 40)

        operators = ['intra_move', 'intra_swap', 'intra_2opt']
        operator_stats = {}

        for truck_id in range(min(3, len(self.dyn_opt.TRUCK_Routes))):  # æµ‹è¯•å‰3ä¸ªè½¦è¾†å¯¹
            if len(self.dyn_opt.TRUCK_Routes[truck_id].Troute) < 4:
                continue

            print(f"\n  è½¦è¾†å¯¹{truck_id}æµ‹è¯•:")

            for op_name in operators:
                # å¤‡ä»½å½“å‰çŠ¶æ€
                backup_truck = copy.deepcopy(self.dyn_opt.TRUCK_Routes[truck_id])
                backup_drone = copy.deepcopy(self.dyn_opt.DRONE_Routes[truck_id])

                # è®°å½•æ“ä½œå‰æˆæœ¬
                cost_before = self.dyn_opt.cost_single_vehicle(truck_id)

                # æ‰§è¡Œå•ä¸ªç®—å­å¤šæ¬¡æµ‹è¯•
                successes = 0
                improvements = []
                execution_times = []

                for _ in range(10):  # æ¯ä¸ªç®—å­æµ‹è¯•10æ¬¡
                    start_time = time.time()

                    try:
                        if op_name == 'intra_move':
                            success = self.dyn_opt._intra_move_within_vehicle(truck_id)
                        elif op_name == 'intra_swap':
                            success = self.dyn_opt._intra_swap_within_vehicle(truck_id)
                        elif op_name == 'intra_2opt':
                            success = self.dyn_opt._intra_2opt_within_vehicle(truck_id)
                        else:
                            success = False

                        execution_time = time.time() - start_time
                        execution_times.append(execution_time)

                        if success:
                            successes += 1
                            cost_after = self.dyn_opt.cost_single_vehicle(truck_id)
                            improvement = cost_before - cost_after
                            improvements.append(improvement)

                            # æ¢å¤çŠ¶æ€ç»§ç»­æµ‹è¯•
                            self.dyn_opt.TRUCK_Routes[truck_id] = copy.deepcopy(backup_truck)
                            self.dyn_opt.DRONE_Routes[truck_id] = copy.deepcopy(backup_drone)

                    except Exception as e:
                        print(f"    âš ï¸ {op_name}æ‰§è¡Œå¼‚å¸¸: {e}")

                # ç»Ÿè®¡è¯¥ç®—å­æ€§èƒ½
                if op_name not in operator_stats:
                    operator_stats[op_name] = {
                        'success_count': 0,
                        'total_tests': 0,
                        'improvements': [],
                        'execution_times': []
                    }

                operator_stats[op_name]['success_count'] += successes
                operator_stats[op_name]['total_tests'] += 10
                operator_stats[op_name]['improvements'].extend(improvements)
                operator_stats[op_name]['execution_times'].extend(execution_times)

                # è¾“å‡ºå•ç®—å­ç»Ÿè®¡
                success_rate = successes / 10 * 100
                avg_improvement = np.mean(improvements) if improvements else 0
                avg_time = np.mean(execution_times) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’

                print(f"    {op_name:15} | æˆåŠŸç‡: {success_rate:5.1f}% | "
                      f"å¹³å‡æ”¹è¿›: {avg_improvement:8.2f} | "
                      f"å¹³å‡è€—æ—¶: {avg_time:6.2f}ms")

                # æ¢å¤åŸå§‹çŠ¶æ€
                self.dyn_opt.TRUCK_Routes[truck_id] = backup_truck
                self.dyn_opt.DRONE_Routes[truck_id] = backup_drone

        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        for op_name, stats in operator_stats.items():
            if stats['total_tests'] > 0:
                stats['success_rate'] = stats['success_count'] / stats['total_tests'] * 100
                stats['avg_improvement'] = np.mean(stats['improvements']) if stats['improvements'] else 0
                stats['avg_execution_time'] = np.mean(stats['execution_times']) if stats['execution_times'] else 0

        self.validation_results['operator_performance'] = operator_stats

        # åˆ¤æ–­æ˜¯å¦æœ‰æ•ˆ
        total_success_rate = sum(s['success_rate'] for s in operator_stats.values()) / len(operator_stats)
        print(f"\n  ğŸ“Š ç®—å­æ€»ä½“æˆåŠŸç‡: {total_success_rate:.1f}%")

        return total_success_rate > 30  # æœŸæœ›è‡³å°‘30%æˆåŠŸç‡

    def track_improvement_patterns(self, num_iterations: int = 10):
        """
        è¿½è¸ªå±€éƒ¨æœç´¢çš„æ”¹è¿›æ¨¡å¼
        """
        print("\nğŸ“Œ æµ‹è¯•3: æ”¹è¿›æ¨¡å¼è¿½è¸ª")
        print("-" * 40)

        improvement_history = []
        cost_history = []

        for iteration in range(num_iterations):
            print(f"\n  è¿­ä»£ {iteration + 1}/{num_iterations}:")

            # éšæœºé€‰æ‹©ä¸€ä¸ªè½¦è¾†å¯¹
            truck_id = np.random.randint(0, len(self.dyn_opt.TRUCK_Routes))

            # è®°å½•åˆå§‹æˆæœ¬
            initial_cost = self.dyn_opt.cost()
            cost_before_ls = initial_cost

            # æ‰§è¡Œå±€éƒ¨æœç´¢
            if self.dyn_opt.enable_local_search:
                try:
                    # å¤‡ä»½çŠ¶æ€
                    backup_state = self._backup_solution_state()

                    # æ‰§è¡Œå±€éƒ¨æœç´¢
                    cost_after_ls = self.dyn_opt.local_search(truck_id, cost_before_ls)

                    improvement = cost_before_ls - cost_after_ls
                    improvement_rate = improvement / cost_before_ls * 100 if cost_before_ls > 0 else 0

                    improvement_history.append({
                        'iteration': iteration,
                        'truck_id': truck_id,
                        'cost_before': cost_before_ls,
                        'cost_after': cost_after_ls,
                        'improvement': improvement,
                        'improvement_rate': improvement_rate
                    })

                    cost_history.append(cost_after_ls)

                    print(f"    è½¦è¾†å¯¹{truck_id}: {cost_before_ls:.2f} â†’ {cost_after_ls:.2f} "
                          f"(æ”¹è¿›: {improvement:.2f}, {improvement_rate:.2f}%)")

                    # æ¢å¤çŠ¶æ€ï¼ˆä¸ºäº†ä¸‹æ¬¡æµ‹è¯•çš„ç‹¬ç«‹æ€§ï¼‰
                    self._restore_solution_state(backup_state)

                except Exception as e:
                    print(f"    âš ï¸ å±€éƒ¨æœç´¢æ‰§è¡Œå¤±è´¥: {e}")
                    cost_history.append(cost_before_ls)

        # åˆ†ææ”¹è¿›æ¨¡å¼
        if improvement_history:
            total_improvements = sum(h['improvement'] for h in improvement_history)
            positive_improvements = sum(1 for h in improvement_history if h['improvement'] > 0)
            improvement_rate = positive_improvements / len(improvement_history) * 100
            avg_improvement = np.mean([h['improvement'] for h in improvement_history])

            print(f"\n  ğŸ“Š æ”¹è¿›æ¨¡å¼åˆ†æ:")
            print(f"     æ€»æ”¹è¿›: {total_improvements:.2f}")
            print(f"     æ”¹è¿›æ¬¡æ•°: {positive_improvements}/{len(improvement_history)}")
            print(f"     æ”¹è¿›ç‡: {improvement_rate:.1f}%")
            print(f"     å¹³å‡æ”¹è¿›: {avg_improvement:.2f}")

            self.validation_results['improvement_tracking'] = {
                'history': improvement_history,
                'total_improvement': total_improvements,
                'improvement_rate': improvement_rate,
                'avg_improvement': avg_improvement
            }

        return improvement_rate > 20  # æœŸæœ›è‡³å°‘20%çš„æ”¹è¿›ç‡

    def analyze_time_efficiency(self):
        """
        åˆ†æå±€éƒ¨æœç´¢çš„æ—¶é—´æ•ˆç‡
        """
        print("\nğŸ“Œ æµ‹è¯•4: æ—¶é—´æ•ˆç‡åˆ†æ")
        print("-" * 40)

        time_stats = {
            'with_ls': [],
            'without_ls': []
        }

        # æµ‹è¯•æœ‰å±€éƒ¨æœç´¢çš„æƒ…å†µ
        print("\n  æµ‹è¯•æœ‰å±€éƒ¨æœç´¢çš„æ‰§è¡Œæ—¶é—´:")
        self.dyn_opt.enable_local_search = True

        for i in range(5):  # æµ‹è¯•5æ¬¡
            truck_id = i % len(self.dyn_opt.TRUCK_Routes)

            start_time = time.time()
            try:
                # æ‰§è¡Œä¸€æ¬¡å®Œæ•´çš„æ›´æ–°æµç¨‹ï¼ˆåŒ…å«å±€éƒ¨æœç´¢ï¼‰
                backup_state = self._backup_solution_state()
                cost_before = self.dyn_opt.cost()

                # æ¨¡æ‹Ÿå±€éƒ¨æœç´¢è°ƒç”¨
                if len(self.dyn_opt.TRUCK_Routes[truck_id].Troute) > 3:
                    self.dyn_opt.local_search(truck_id, cost_before)

                execution_time = time.time() - start_time
                time_stats['with_ls'].append(execution_time)

                print(f"    æµ‹è¯•{i + 1}: {execution_time * 1000:.2f}ms")

                # æ¢å¤çŠ¶æ€
                self._restore_solution_state(backup_state)

            except Exception as e:
                print(f"    âš ï¸ æµ‹è¯•{i + 1}å¤±è´¥: {e}")

        # æµ‹è¯•æ— å±€éƒ¨æœç´¢çš„æƒ…å†µ
        print("\n  æµ‹è¯•æ— å±€éƒ¨æœç´¢çš„æ‰§è¡Œæ—¶é—´:")
        self.dyn_opt.enable_local_search = False

        for i in range(5):
            truck_id = i % len(self.dyn_opt.TRUCK_Routes)

            start_time = time.time()
            try:
                # æ‰§è¡Œä¸€æ¬¡æ›´æ–°æµç¨‹ï¼ˆä¸åŒ…å«å±€éƒ¨æœç´¢ï¼‰
                backup_state = self._backup_solution_state()

                # åªæ‰§è¡ŒåŸºæœ¬æ“ä½œ
                if len(self.dyn_opt.TRUCK_Routes[truck_id].Troute) > 3:
                    # æ¨¡æ‹Ÿä¸€äº›åŸºæœ¬æ“ä½œ
                    _ = self.dyn_opt.cost_single_vehicle(truck_id)

                execution_time = time.time() - start_time
                time_stats['without_ls'].append(execution_time)

                print(f"    æµ‹è¯•{i + 1}: {execution_time * 1000:.2f}ms")

                # æ¢å¤çŠ¶æ€
                self._restore_solution_state(backup_state)

            except Exception as e:
                print(f"    âš ï¸ æµ‹è¯•{i + 1}å¤±è´¥: {e}")

        # æ¢å¤åŸå§‹è®¾ç½®
        self.dyn_opt.enable_local_search = True

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        if time_stats['with_ls'] and time_stats['without_ls']:
            avg_with_ls = np.mean(time_stats['with_ls']) * 1000
            avg_without_ls = np.mean(time_stats['without_ls']) * 1000
            time_overhead = avg_with_ls - avg_without_ls
            overhead_rate = time_overhead / avg_without_ls * 100 if avg_without_ls > 0 else 0

            print(f"\n  ğŸ“Š æ—¶é—´æ•ˆç‡åˆ†æ:")
            print(f"     æœ‰å±€éƒ¨æœç´¢å¹³å‡è€—æ—¶: {avg_with_ls:.2f}ms")
            print(f"     æ— å±€éƒ¨æœç´¢å¹³å‡è€—æ—¶: {avg_without_ls:.2f}ms")
            print(f"     é¢å¤–å¼€é”€: {time_overhead:.2f}ms ({overhead_rate:.1f}%)")

            self.validation_results['time_analysis'] = {
                'avg_with_ls': avg_with_ls,
                'avg_without_ls': avg_without_ls,
                'overhead': time_overhead,
                'overhead_rate': overhead_rate
            }

            return overhead_rate < 200  # æœŸæœ›å¼€é”€ä¸è¶…è¿‡200%

        return False

    def analyze_convergence_behavior(self):
        """
        åˆ†æå±€éƒ¨æœç´¢çš„æ”¶æ•›è¡Œä¸º
        """
        print("\nğŸ“Œ æµ‹è¯•5: æ”¶æ•›è¡Œä¸ºåˆ†æ")
        print("-" * 40)

        convergence_data = []

        # é€‰æ‹©ä¸€ä¸ªè½¦è¾†å¯¹è¿›è¡Œæ·±å…¥åˆ†æ
        truck_id = 0
        if len(self.dyn_opt.TRUCK_Routes[truck_id].Troute) < 4:
            print("  âš ï¸ è½¦è¾†å¯¹0è·¯å¾„å¤ªçŸ­ï¼Œè·³è¿‡æ”¶æ•›åˆ†æ")
            return False

        # å¤‡ä»½åˆå§‹çŠ¶æ€
        initial_backup = self._backup_solution_state()

        # è®¾ç½®å±€éƒ¨æœç´¢å‚æ•°
        original_max_no_improve = self.dyn_opt.local_search_max_no_improve
        self.dyn_opt.local_search_max_no_improve = 20  # å¢åŠ è¿­ä»£æ¬¡æ•°ä»¥è§‚å¯Ÿæ”¶æ•›

        # æ‰§è¡Œå¤šè½®å±€éƒ¨æœç´¢ï¼Œè®°å½•æ¯è½®çš„æˆæœ¬
        print(f"\n  å¯¹è½¦è¾†å¯¹{truck_id}æ‰§è¡Œè¿ç»­å±€éƒ¨æœç´¢:")

        current_cost = self.dyn_opt.cost()
        for round_num in range(10):  # æ‰§è¡Œ10è½®
            round_start_cost = current_cost

            try:
                # æ‰§è¡Œå±€éƒ¨æœç´¢
                new_cost = self.dyn_opt.local_search(truck_id, current_cost)
                improvement = current_cost - new_cost

                convergence_data.append({
                    'round': round_num + 1,
                    'start_cost': round_start_cost,
                    'end_cost': new_cost,
                    'improvement': improvement
                })

                print(f"    ç¬¬{round_num + 1}è½®: {round_start_cost:.2f} â†’ {new_cost:.2f} "
                      f"(æ”¹è¿›: {improvement:.2f})")

                current_cost = new_cost

                # å¦‚æœæ²¡æœ‰æ”¹è¿›ï¼Œè¯´æ˜å·²æ”¶æ•›
                if improvement < 0.001:
                    print(f"    âœ… åœ¨ç¬¬{round_num + 1}è½®è¾¾åˆ°æ”¶æ•›")
                    break

            except Exception as e:
                print(f"    âš ï¸ ç¬¬{round_num + 1}è½®æ‰§è¡Œå¤±è´¥: {e}")
                break

        # æ¢å¤è®¾ç½®
        self.dyn_opt.local_search_max_no_improve = original_max_no_improve
        self._restore_solution_state(initial_backup)

        # åˆ†ææ”¶æ•›ç‰¹æ€§
        if convergence_data:
            improvements = [d['improvement'] for d in convergence_data]
            converged_round = next((i for i, imp in enumerate(improvements) if imp < 0.001), -1)

            print(f"\n  ğŸ“Š æ”¶æ•›åˆ†æ:")
            print(f"     æ€»è½®æ•°: {len(convergence_data)}")
            print(f"     æ”¶æ•›è½®æ¬¡: {converged_round + 1 if converged_round >= 0 else 'æœªæ”¶æ•›'}")
            print(f"     æ€»æ”¹è¿›: {sum(improvements):.2f}")
            print(f"     æ”¹è¿›é€’å‡ç‡: {self._calculate_decay_rate(improvements):.2f}%")

            self.validation_results['convergence_analysis'] = {
                'data': convergence_data,
                'converged_at': converged_round + 1 if converged_round >= 0 else None,
                'total_improvement': sum(improvements)
            }

            return converged_round >= 0  # æœŸæœ›èƒ½å¤Ÿæ”¶æ•›

        return False

    def comparative_analysis(self, num_tests: int = 10):
        """
        æœ‰/æ— å±€éƒ¨æœç´¢çš„å¯¹æ¯”åˆ†æ
        """
        print("\nğŸ“Œ æµ‹è¯•6: æœ‰/æ— å±€éƒ¨æœç´¢å¯¹æ¯”åˆ†æ")
        print("-" * 40)

        results_with_ls = []
        results_without_ls = []

        # å¤‡ä»½åˆå§‹çŠ¶æ€
        initial_backup = self._backup_solution_state()

        print("\n  æ‰§è¡Œå¯¹æ¯”æµ‹è¯•:")

        for test_id in range(num_tests):
            # æ¯æ¬¡æµ‹è¯•éƒ½ä»ç›¸åŒçš„åˆå§‹çŠ¶æ€å¼€å§‹
            self._restore_solution_state(initial_backup)

            # éšæœºé€‰æ‹©ä¸€ä¸ªè½¦è¾†å¯¹å’Œå®¢æˆ·è¿›è¡Œæµ‹è¯•
            truck_id = test_id % len(self.dyn_opt.TRUCK_Routes)
            if len(self.dyn_opt.get_vehicle_customers(truck_id)) < 3:
                continue

            customers = list(self.dyn_opt.get_vehicle_customers(truck_id))
            if customers:
                customer_id = np.random.choice(customers)
            else:
                continue

            # æµ‹è¯•æœ‰å±€éƒ¨æœç´¢çš„æƒ…å†µ
            self.dyn_opt.enable_local_search = True
            self.dyn_opt.ls_operation_count = 0  # é‡ç½®è®¡æ•°å™¨

            cost_before = self.dyn_opt.cost()

            try:
                # æ¨¡æ‹Ÿä¸€æ¬¡è·¯å¾„æ›´æ–°ï¼ˆä¼šè§¦å‘å±€éƒ¨æœç´¢ï¼‰
                self.dyn_opt.update_route(1, customer_id, ['tk', truck_id])
                cost_with_ls = self.dyn_opt.cost()

                results_with_ls.append({
                    'test_id': test_id,
                    'cost_before': cost_before,
                    'cost_after': cost_with_ls,
                    'improvement': cost_before - cost_with_ls
                })

            except Exception as e:
                print(f"    âš ï¸ æµ‹è¯•{test_id + 1}(æœ‰LS)å¤±è´¥: {e}")

            # æ¢å¤åˆå§‹çŠ¶æ€
            self._restore_solution_state(initial_backup)

            # æµ‹è¯•æ— å±€éƒ¨æœç´¢çš„æƒ…å†µ
            self.dyn_opt.enable_local_search = False

            try:
                # æ‰§è¡Œç›¸åŒçš„è·¯å¾„æ›´æ–°ï¼ˆä¸ä¼šè§¦å‘å±€éƒ¨æœç´¢ï¼‰
                self.dyn_opt.update_route(1, customer_id, ['tk', truck_id])
                cost_without_ls = self.dyn_opt.cost()

                results_without_ls.append({
                    'test_id': test_id,
                    'cost_before': cost_before,
                    'cost_after': cost_without_ls,
                    'improvement': cost_before - cost_without_ls
                })

            except Exception as e:
                print(f"    âš ï¸ æµ‹è¯•{test_id + 1}(æ— LS)å¤±è´¥: {e}")

            # æ¢å¤åˆå§‹çŠ¶æ€
            self._restore_solution_state(initial_backup)

        # æ¢å¤å±€éƒ¨æœç´¢è®¾ç½®
        self.dyn_opt.enable_local_search = True

        # åˆ†æå¯¹æ¯”ç»“æœ
        if results_with_ls and results_without_ls:
            avg_improvement_with_ls = np.mean([r['improvement'] for r in results_with_ls])
            avg_improvement_without_ls = np.mean([r['improvement'] for r in results_without_ls])

            improvement_difference = avg_improvement_with_ls - avg_improvement_without_ls

            print(f"\n  ğŸ“Š å¯¹æ¯”åˆ†æç»“æœ:")
            print(f"     æœ‰å±€éƒ¨æœç´¢å¹³å‡æ”¹è¿›: {avg_improvement_with_ls:.2f}")
            print(f"     æ— å±€éƒ¨æœç´¢å¹³å‡æ”¹è¿›: {avg_improvement_without_ls:.2f}")
            print(f"     å±€éƒ¨æœç´¢é¢å¤–è´¡çŒ®: {improvement_difference:.2f}")

            # ç»Ÿè®¡æ˜¾è‘—æ”¹è¿›çš„æ¯”ä¾‹
            significant_improvements = sum(
                1 for w, wo in zip(results_with_ls, results_without_ls)
                if w['improvement'] > wo['improvement'] + 0.01
            )
            improvement_rate = significant_improvements / len(results_with_ls) * 100

            print(f"     æ˜¾è‘—æ”¹è¿›æ¯”ä¾‹: {improvement_rate:.1f}%")

            return improvement_difference > 0  # æœŸæœ›å±€éƒ¨æœç´¢å¸¦æ¥æ­£é¢è´¡çŒ®

        return False

    def generate_validation_report(self):
        """
        ç”Ÿæˆç»¼åˆéªŒè¯æŠ¥å‘Š
        """
        print("\n" + "=" * 80)
        print("ğŸ“‹ å±€éƒ¨æœç´¢æœ‰æ•ˆæ€§éªŒè¯æŠ¥å‘Š")
        print("=" * 80)

        # 1. è§¦å‘æœºåˆ¶è¯„ä¼°
        if 'trigger_analysis' in self.validation_results:
            trigger_rate = self.validation_results['trigger_analysis']['trigger_rate']
            verdict = "âœ… æ­£å¸¸" if trigger_rate > 50 else "âŒ å¼‚å¸¸"
            print(f"\n1. è§¦å‘æœºåˆ¶: {verdict}")
            print(f"   - è§¦å‘ç‡: {trigger_rate:.1f}%")

        # 2. ç®—å­æ€§èƒ½è¯„ä¼°
        if 'operator_performance' in self.validation_results:
            operator_stats = self.validation_results['operator_performance']
            print(f"\n2. ç®—å­æ€§èƒ½:")
            for op_name, stats in operator_stats.items():
                if 'success_rate' in stats:
                    print(f"   - {op_name}: æˆåŠŸç‡={stats['success_rate']:.1f}%, "
                          f"å¹³å‡æ”¹è¿›={stats['avg_improvement']:.2f}")

        # 3. æ”¹è¿›æ•ˆæœè¯„ä¼°
        if 'improvement_tracking' in self.validation_results:
            tracking = self.validation_results['improvement_tracking']
            verdict = "âœ… æœ‰æ•ˆ" if tracking.get('improvement_rate', 0) > 20 else "âš ï¸ æ•ˆæœæœ‰é™"
            print(f"\n3. æ”¹è¿›æ•ˆæœ: {verdict}")
            print(f"   - æ”¹è¿›ç‡: {tracking.get('improvement_rate', 0):.1f}%")
            print(f"   - å¹³å‡æ”¹è¿›: {tracking.get('avg_improvement', 0):.2f}")

        # 4. æ—¶é—´æ•ˆç‡è¯„ä¼°
        if 'time_analysis' in self.validation_results:
            time_analysis = self.validation_results['time_analysis']
            overhead = time_analysis.get('overhead_rate', 0)
            verdict = "âœ… å¯æ¥å—" if overhead < 200 else "âš ï¸ å¼€é”€è¾ƒå¤§"
            print(f"\n4. æ—¶é—´æ•ˆç‡: {verdict}")
            print(f"   - é¢å¤–å¼€é”€: {overhead:.1f}%")

        # 5. æ”¶æ•›æ€§è¯„ä¼°
        if 'convergence_analysis' in self.validation_results:
            convergence = self.validation_results['convergence_analysis']
            converged = convergence.get('converged_at')
            verdict = "âœ… è‰¯å¥½" if converged else "âš ï¸ æœªæ”¶æ•›"
            print(f"\n5. æ”¶æ•›æ€§: {verdict}")
            if converged:
                print(f"   - æ”¶æ•›è½®æ¬¡: {converged}")

        # æ€»ä½“è¯„ä¼°
        print("\n" + "=" * 80)
        print("ğŸ“Š æ€»ä½“è¯„ä¼°:")

        effectiveness_score = self._calculate_effectiveness_score()

        if effectiveness_score >= 80:
            print("   âœ… å±€éƒ¨æœç´¢æ¨¡å—å·¥ä½œæ­£å¸¸ä¸”æœ‰æ•ˆ")
        elif effectiveness_score >= 50:
            print("   âš ï¸ å±€éƒ¨æœç´¢æ¨¡å—åŸºæœ¬æœ‰æ•ˆï¼Œä½†æœ‰æ”¹è¿›ç©ºé—´")
        else:
            print("   âŒ å±€éƒ¨æœç´¢æ¨¡å—æ•ˆæœä¸ä½³ï¼Œéœ€è¦ä¼˜åŒ–")

        print(f"   ç»¼åˆå¾—åˆ†: {effectiveness_score:.1f}/100")
        print("=" * 80)

    def _backup_solution_state(self):
        """å¤‡ä»½å½“å‰è§£çŠ¶æ€"""
        return {
            'truck_routes': copy.deepcopy(self.dyn_opt.TRUCK_Routes),
            'drone_routes': copy.deepcopy(self.dyn_opt.DRONE_Routes),
            'customers': copy.deepcopy(self.dyn_opt.customers)
        }

    def _restore_solution_state(self, backup):
        """æ¢å¤è§£çŠ¶æ€"""
        self.dyn_opt.TRUCK_Routes = copy.deepcopy(backup['truck_routes'])
        self.dyn_opt.DRONE_Routes = copy.deepcopy(backup['drone_routes'])
        self.dyn_opt.customers = copy.deepcopy(backup['customers'])

    def _calculate_decay_rate(self, improvements):
        """è®¡ç®—æ”¹è¿›é€’å‡ç‡"""
        if len(improvements) < 2:
            return 0

        decay_rates = []
        for i in range(1, len(improvements)):
            if improvements[i - 1] > 0:
                rate = (improvements[i - 1] - improvements[i]) / improvements[i - 1] * 100
                decay_rates.append(rate)

        return np.mean(decay_rates) if decay_rates else 0

    def _calculate_effectiveness_score(self):
        """è®¡ç®—å±€éƒ¨æœç´¢æœ‰æ•ˆæ€§ç»¼åˆå¾—åˆ†"""
        score = 0
        weights = {
            'trigger': 20,
            'operators': 20,
            'improvement': 25,
            'time': 15,
            'convergence': 20
        }

        # è§¦å‘æœºåˆ¶å¾—åˆ†
        if 'trigger_analysis' in self.validation_results:
            trigger_rate = self.validation_results['trigger_analysis']['trigger_rate']
            score += weights['trigger'] * min(trigger_rate / 70, 1)

        # ç®—å­æ€§èƒ½å¾—åˆ†
        if 'operator_performance' in self.validation_results:
            operator_stats = self.validation_results['operator_performance']
            if operator_stats:
                avg_success = np.mean([s.get('success_rate', 0) for s in operator_stats.values()])
                score += weights['operators'] * min(avg_success / 40, 1)

        # æ”¹è¿›æ•ˆæœå¾—åˆ†
        if 'improvement_tracking' in self.validation_results:
            improvement_rate = self.validation_results['improvement_tracking'].get('improvement_rate', 0)
            score += weights['improvement'] * min(improvement_rate / 30, 1)

        # æ—¶é—´æ•ˆç‡å¾—åˆ†
        if 'time_analysis' in self.validation_results:
            overhead = self.validation_results['time_analysis'].get('overhead_rate', 999)
            if overhead < 200:
                score += weights['time'] * (1 - min(overhead / 200, 1))

        # æ”¶æ•›æ€§å¾—åˆ†
        if 'convergence_analysis' in self.validation_results:
            if self.validation_results['convergence_analysis'].get('converged_at'):
                score += weights['convergence']

        return score


def visualize_local_search_performance(validator: LocalSearchValidator):
    """
    å¯è§†åŒ–å±€éƒ¨æœç´¢æ€§èƒ½åˆ†æç»“æœ
    """
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    fig.suptitle('å±€éƒ¨æœç´¢æ€§èƒ½åˆ†æå¯è§†åŒ–', fontsize=16)

    # 1. è§¦å‘ç‡æ¡å½¢å›¾
    ax1 = axes[0, 0]
    if 'trigger_analysis' in validator.validation_results:
        trigger_data = validator.validation_results['trigger_analysis']['tests']
        scenarios = list(set(t['scenario'] for t in trigger_data))
        trigger_rates = [
            sum(1 for t in trigger_data if t['scenario'] == s and t['triggered']) /
            sum(1 for t in trigger_data if t['scenario'] == s) * 100
            for s in scenarios
        ]
        ax1.bar(range(len(scenarios)), trigger_rates)
        ax1.set_xticks(range(len(scenarios)))
        ax1.set_xticklabels(scenarios, rotation=45, ha='right')
        ax1.set_ylabel('è§¦å‘ç‡ (%)')
        ax1.set_title('ä¸åŒåœºæ™¯è§¦å‘ç‡')

    # 2. ç®—å­æˆåŠŸç‡
    ax2 = axes[0, 1]
    if 'operator_performance' in validator.validation_results:
        operator_stats = validator.validation_results['operator_performance']
        operators = list(operator_stats.keys())
        success_rates = [operator_stats[op].get('success_rate', 0) for op in operators]
        ax2.bar(operators, success_rates)
        ax2.set_ylabel('æˆåŠŸç‡ (%)')
        ax2.set_title('ç®—å­æˆåŠŸç‡å¯¹æ¯”')

    # 3. æ”¹è¿›è¶‹åŠ¿
    ax3 = axes[0, 2]
    if 'improvement_tracking' in validator.validation_results:
        history = validator.validation_results['improvement_tracking'].get('history', [])
        if history:
            iterations = [h['iteration'] for h in history]
            improvements = [h['improvement'] for h in history]
            ax3.plot(iterations, improvements, 'b-o')
            ax3.axhline(y=0, color='r', linestyle='--', alpha=0.5)
            ax3.set_xlabel('è¿­ä»£æ¬¡æ•°')
            ax3.set_ylabel('æ”¹è¿›å€¼')
            ax3.set_title('æ”¹è¿›è¶‹åŠ¿')

    # 4. æ—¶é—´å¼€é”€å¯¹æ¯”
    ax4 = axes[1, 0]
    if 'time_analysis' in validator.validation_results:
        time_data = validator.validation_results['time_analysis']
        categories = ['æ— å±€éƒ¨æœç´¢', 'æœ‰å±€éƒ¨æœç´¢']
        times = [time_data.get('avg_without_ls', 0), time_data.get('avg_with_ls', 0)]
        ax4.bar(categories, times)
        ax4.set_ylabel('å¹³å‡è€—æ—¶ (ms)')
        ax4.set_title('æ—¶é—´å¼€é”€å¯¹æ¯”')

    # 5. æ”¶æ•›æ›²çº¿
    ax5 = axes[1, 1]
    if 'convergence_analysis' in validator.validation_results:
        convergence_data = validator.validation_results['convergence_analysis'].get('data', [])
        if convergence_data:
            rounds = [d['round'] for d in convergence_data]
            costs = [d['end_cost'] for d in convergence_data]
            ax5.plot(rounds, costs, 'g-o')
            ax5.set_xlabel('è½®æ¬¡')
            ax5.set_ylabel('æˆæœ¬')
            ax5.set_title('æ”¶æ•›è¡Œä¸º')

    # 6. ç»¼åˆè¯„åˆ†é›·è¾¾å›¾
    ax6 = axes[1, 2]
    scores = validator._calculate_component_scores()
    if scores:
        categories = list(scores.keys())
        values = list(scores.values())

        # åˆ›å»ºé›·è¾¾å›¾
        angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()
        values += values[:1]  # é—­åˆ
        angles += angles[:1]

        ax6 = plt.subplot(2, 3, 6, projection='polar')
        ax6.plot(angles, values, 'b-o')
        ax6.fill(angles, values, alpha=0.25)
        ax6.set_xticks(angles[:-1])
        ax6.set_xticklabels(categories)
        ax6.set_ylim(0, 100)
        ax6.set_title('ç»¼åˆæ€§èƒ½è¯„åˆ†')

    plt.tight_layout()
    plt.show()


def test_local_search_effectiveness(dynamic_optimizer):
    """
    ä¸»æµ‹è¯•å‡½æ•°ï¼šå…¨é¢æµ‹è¯•å±€éƒ¨æœç´¢æœ‰æ•ˆæ€§
    """
    print("\n" + "=" * 80)
    print("ğŸš€ å¼€å§‹å±€éƒ¨æœç´¢æœ‰æ•ˆæ€§æµ‹è¯•")
    print("=" * 80)

    # åˆ›å»ºéªŒè¯å™¨
    validator = LocalSearchValidator(dynamic_optimizer)

    # è¿è¡Œç»¼åˆéªŒè¯
    results = validator.run_comprehensive_validation(num_tests=5)

    # å¯è§†åŒ–ç»“æœ
    try:
        visualize_local_search_performance(validator)
    except Exception as e:
        print(f"\nâš ï¸ å¯è§†åŒ–å¤±è´¥: {e}")

    # æä¾›æ”¹è¿›å»ºè®®
    print("\n" + "=" * 80)
    print("ğŸ’¡ æ”¹è¿›å»ºè®®:")
    print("=" * 80)

    if results.get('trigger_analysis', {}).get('trigger_rate', 0) < 50:
        print("1. âš ï¸ è§¦å‘ç‡åä½ï¼Œå»ºè®®:")
        print("   - è°ƒæ•´thetaé˜ˆå€¼ï¼Œå½“å‰å€¼å¯èƒ½è¿‡äºä¸¥æ ¼")
        print("   - è€ƒè™‘å¢åŠ é¢‘ç‡è§¦å‘ç­–ç•¥")

    if results.get('operator_performance'):
        low_performers = [
            op for op, stats in results['operator_performance'].items()
            if stats.get('success_rate', 0) < 20
        ]
        if low_performers:
            print(f"2. âš ï¸ ä½æ•ˆç®—å­: {low_performers}")
            print("   - æ£€æŸ¥ç®—å­å®ç°é€»è¾‘")
            print("   - è€ƒè™‘çº¦æŸæ¡ä»¶æ˜¯å¦è¿‡äºä¸¥æ ¼")

    if results.get('improvement_tracking', {}).get('improvement_rate', 0) < 20:
        print("3. âš ï¸ æ”¹è¿›ç‡åä½ï¼Œå»ºè®®:")
        print("   - å¢åŠ å±€éƒ¨æœç´¢è¿­ä»£æ¬¡æ•°")
        print("   - å°è¯•æ›´æ¿€è¿›çš„é‚»åŸŸæ“ä½œ")
        print("   - è€ƒè™‘å®ç°inter-routeç®—å­")

    if results.get('time_analysis', {}).get('overhead_rate', 0) > 200:
        print("4. âš ï¸ æ—¶é—´å¼€é”€è¿‡å¤§ï¼Œå»ºè®®:")
        print("   - å‡å°‘max_no_improveå‚æ•°")
        print("   - å®ç°early stoppingæœºåˆ¶")
        print("   - è€ƒè™‘æ¦‚ç‡æ€§è§¦å‘")

    print("\næµ‹è¯•å®Œæˆï¼")
    return results


# æ·»åŠ åˆ°LocalSearchValidatorç±»ä¸­çš„è¾…åŠ©æ–¹æ³•
def _calculate_component_scores(self):
    """è®¡ç®—å„ç»„ä»¶å¾—åˆ†ï¼ˆç”¨äºé›·è¾¾å›¾ï¼‰"""
    scores = {}

    if 'trigger_analysis' in self.validation_results:
        scores['è§¦å‘æœºåˆ¶'] = min(self.validation_results['trigger_analysis']['trigger_rate'], 100)

    if 'operator_performance' in self.validation_results:
        operator_stats = self.validation_results['operator_performance']
        if operator_stats:
            avg_success = np.mean([s.get('success_rate', 0) for s in operator_stats.values()])
            scores['ç®—å­æ€§èƒ½'] = min(avg_success * 2, 100)

    if 'improvement_tracking' in self.validation_results:
        scores['æ”¹è¿›æ•ˆæœ'] = min(self.validation_results['improvement_tracking'].get('improvement_rate', 0) * 3, 100)

    if 'time_analysis' in self.validation_results:
        overhead = self.validation_results['time_analysis'].get('overhead_rate', 999)
        scores['æ—¶é—´æ•ˆç‡'] = max(0, 100 - min(overhead, 100))

    if 'convergence_analysis' in self.validation_results:
        scores['æ”¶æ•›æ€§'] = 100 if self.validation_results['convergence_analysis'].get('converged_at') else 0

    return scores


# å°†è¿™ä¸ªæ–¹æ³•æ·»åŠ åˆ°LocalSearchValidatorç±»ä¸­
LocalSearchValidator._calculate_component_scores = _calculate_component_scores